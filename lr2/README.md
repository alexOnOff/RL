# Лабораторная работа №2. 
## Конечные марковские процессы принятия решений - конечные МППР

В этой лабе мы поиграем в сеточный мир. 
Существует поле 5х5 (при желании в программе можно сделать мир и больше), при выходе за пределы мира штрафуем агента на -1, при хождении по миру награда - 0, при попадании в "волшебные" клетки переносим агента в указанную в клетке позицию и награждаем его большим пирожком.

Необходимо было проверить выполнение уравнения Беллмана на поле со следующими значениями функции ценности состояния:

    3.3    8.8    4.4    5.3    1.5
    1.5      3    2.3    1.9    0.5
    0.1    0.7    0.7    0.4   -0.4
     -1   -0.4   -0.4   -0.6   -1.2
    -1.9   -1.3   -1.2   -1.4     -2

При создании такого поля вызвать StudyOnce, то получим:

    3.3   8.83   4.43   5.36   1.48
    1.53   2.99   2.25   1.91   0.54
    0.04   0.77   0.67   0.36  -0.41
    -0.97  -0.45  -0.34  -0.59  -1.19
    -1.87  -1.33  -1.22  -1.42  -1.99

Вроде как этого было достаточно.

Но я реализовал еще и обучение по политике выбора рандомного хода (вверх, вниз, влево, вправо). Начальная матрица функции ценности состояния заполнена нулями. При одной итерации обучения получим:

    -0.5     10  -0.25      5   -0.5
    -0.25      0      0      0  -0.25
    -0.25      0      0      0  -0.25
    -0.25      0      0      0  -0.25
    -0.5  -0.25  -0.25  -0.25   -0.5

100 итераций:

    3.31   8.79   4.43   5.32   1.49
    1.52   2.99   2.25   1.91   0.55
    0.05   0.74   0.67   0.36   -0.4
    -0.97  -0.44  -0.35  -0.59  -1.18
    -1.86  -1.35  -1.23  -1.42  -1.98

10000 итераций:

    3.31   8.79   4.43   5.32   1.49
    1.52   2.99   2.25   1.91   0.55
    0.05   0.74   0.67   0.36   -0.4
    -0.97  -0.44  -0.35  -0.59  -1.18
    -1.86  -1.35  -1.23  -1.42  -1.98

При такой политике уравнение начнет сходиться уже при 100 итерациях "обучения" (Если это можно так назвать)

В целом, полсе этого обучения можно будет ставить на карту агента и запускать его в путешествие, политика будет такой: следующее состояние должно быть максимальным, среди всех возможных.
И все получится, как на картинке из методички. 